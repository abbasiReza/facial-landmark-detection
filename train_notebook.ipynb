{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# from torchlm.models import pipnet\n",
    "# # will auto download pretrained weights from latest release if pretrained=True\n",
    "# model = pipnet(backbone=\"resnet101\", pretrained=True, num_nb=10, num_lms=98, net_stride=32,\n",
    "#                input_size=256, meanface_type=\"300w\", backbone_pretrained=True)\n",
    "# model.apply_freezing(backbone=True)\n",
    "# model.apply_training(\n",
    "#     annotation_path=\"E:/code/landmark/data/300w/images/train.txt\",  # or fine-tuning your custom data\n",
    "#     num_epochs=10,\n",
    "#     learning_rate=0.0001,\n",
    "#     save_dir=\"E:/code/landmark/data/300w/images\",\n",
    "#     save_prefix=\"pipnet-300w-resnet1101\",\n",
    "#     save_interval=1,\n",
    "#     logging_interval=1,\n",
    "#     device=\"cuda\",\n",
    "#     coordinates_already_normalized=True,\n",
    "#     batch_size=16,\n",
    "#     num_workers=4,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "\n",
    "from torchlm.models import pipnet\n",
    "import torchlm\n",
    "# will auto download pretrained weights from latest release if pretrained=True\n",
    "model = pipnet(backbone=\"resnet101\", pretrained=True, num_nb=10, num_lms=98, net_stride=32,\n",
    "               input_size=256, meanface_type=\"wflw\", backbone_pretrained=True)\n",
    "# model.apply_freezing(backbone=True)\n",
    "# generate your custom meanface.\n",
    "custom_meanface, custom_meanface_string = torchlm.data.annotools.generate_meanface(\n",
    "  annotation_path=\"E:/code/landmark/daghigihi/train2.txt\",\n",
    "  coordinates_already_normalized=True)\n",
    "\n",
    "# setting up your custom meanface\n",
    "model.set_custom_meanface(custom_meanface_file_or_string=custom_meanface_string)\n",
    "model.apply_training(\n",
    "    annotation_path=\"E:/code/landmark/daghigihi/train2.txt\",  # or fine-tuning your custom data\n",
    "    num_epochs=1,\n",
    "    learning_rate=0,\n",
    "    save_dir=\"./save/pipnet\",\n",
    "    save_prefix=\"pipnet-wflw-resnet101\",\n",
    "    save_interval=2,\n",
    "    logging_interval=1,\n",
    "    device=\"cuda\",\n",
    "    coordinates_already_normalized=True,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# from torchlm.models import pipnet\n",
    "# # will auto download pretrained weights from latest release if pretrained=True\n",
    "# model = pipnet(backbone=\"resnet101\", pretrained=True, num_nb=10, num_lms=98, net_stride=32,\n",
    "#                input_size=256, meanface_type=\"300w\", backbone_pretrained=True)\n",
    "# model.apply_freezing(backbone=True)\n",
    "# model.apply_training(\n",
    "#     annotation_path=\"E:/code/landmark/data/300w/images/train.txt\",  # or fine-tuning your custom data\n",
    "#     num_epochs=10,\n",
    "#     learning_rate=0.0001,\n",
    "#     save_dir=\"E:/code/landmark/data/300w/images\",\n",
    "#     save_prefix=\"pipnet-300w-resnet1101\",\n",
    "#     save_interval=1,\n",
    "#     logging_interval=1,\n",
    "#     device=\"cuda\",\n",
    "#     coordinates_already_normalized=True,\n",
    "#     batch_size=16,\n",
    "#     num_workers=4,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "\n",
    "from torchlm.models import pipnet\n",
    "import torchlm\n",
    "# will auto download pretrained weights from latest release if pretrained=True\n",
    "model = pipnet(backbone=\"resnet101\", pretrained=True, num_nb=10, num_lms=98, net_stride=32,\n",
    "               input_size=256, meanface_type=\"wflw\", backbone_pretrained=True)\n",
    "# generate your custom meanface.\n",
    "custom_meanface, custom_meanface_string = torchlm.data.annotools.generate_meanface(\n",
    "  annotation_path=\"E:/code/landmark/daghigihi/train2.txt\",\n",
    "  coordinates_already_normalized=True)\n",
    "\n",
    "# setting up your custom meanface\n",
    "model.set_custom_meanface(custom_meanface_file_or_string=custom_meanface_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.save(model.state_dict(),'yasam.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('yasam.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NME, FR, AUC = model.apply_evaluating(\n",
    "    annotation_path=\"E:/code/landmark/daghigihi/test2.txt\",\n",
    "    norm_indices=[24, 25],  # the indexes of two eyeballs.\n",
    "    coordinates_already_normalized=True, \n",
    "    eval_normalized_coordinates=False\n",
    ")\n",
    "print(f\"NME: {NME}, FR: {FR}, AUC: {AUC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('E:/code/landmark/save/pipnet/pipnet-wflw-resnet101-epoch40-loss0.9896.pth'))\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read an image file into a NumPy array\n",
    "# Read an image file into a NumPy array\n",
    "# img = plt.imread('E:/code/landmark/data/300w/images/image/train/21afw_1648807314_2.jpg')\n",
    "# img = plt.imread('E:/code/landmark/our_dataset/image/train/62train_194.jpg')\n",
    "img = plt.imread('E:/code/landmark/our_dataset/image/test/test_106.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grandtruth='0.50979066 0.31262526 0.5185685 0.40230462 0.52126944 0.6142284 0.5205942 0.66182363 0.50911546 0.72795594 0.5118163 0.748497 0.5118163 0.748497 0.51654285 0.8041082 0.51654285 0.8116233 0.5307225 0.91683364 0.59081703 0.38276553 0.45037138 0.38426852 0.77177584 0.31763527 0.25455773 0.3216433 0.6130993 0.4529058 0.41458473 0.45390782 0.69682646 0.42935872 0.32140446 0.42985973 0.7947333 0.43286574 0.2295746 0.43687373 0.5671843 0.42985973 0.46049967 0.43136272 0.6205267 0.61873746 0.40175557 0.6247495 0.55367994 0.71693385 0.46117488 0.7149299 0.67116815 0.7324649 0.35178933 0.73547095 0.812289 0.5616233 0.916948 0.50701404 0.19311276 0.5556112 0.08372721 0.5 0.84604996 0.31563127 0.17420661 0.3236473 0.84672517 0.7274549 0.17555706 0.751002'.split(' ')\n",
    "x_g=[]\n",
    "y_g=[]\n",
    "for i in range(0,len(grandtruth),2):\n",
    "    x_g.append(float(grandtruth[i])*256)\n",
    "\n",
    "for i in range(1,len(grandtruth),2):\n",
    "    y_g.append(float(grandtruth[i])*256)\n",
    "x_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.apply_detecting(image=img)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "xx=torch.load('lms_pred_x.pt')*256\n",
    "yy=torch.load('lms_pred_y.pt')*256\n",
    "x=[]\n",
    "y=[]\n",
    "for a in xx.cpu():\n",
    "    x.append(a.item())\n",
    "for a in yy:\n",
    "    y.append(a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=out[:,0]\n",
    "y2=out[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=16\n",
    "# ax.scatter(x[k], y[k], c='r')\n",
    "# ax.scatter(x_g[15], y_g[15], c='g')\n",
    "ax.scatter(x, y, c='r')\n",
    "# ax.scatter(x_g, y_g, c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=17\n",
    "# ax.scatter(x[k], y[k], c='r')\n",
    "# ax.scatter(x_g[15], y_g[15], c='g')\n",
    "ax.scatter(x2[k], y2[k], c='r')\n",
    "# ax.scatter(x_g, y_g, c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=17\n",
    "# ax.scatter(x[k], y[k], c='r')\n",
    "# ax.scatter(x_g[15], y_g[15], c='g')\n",
    "ax.scatter(x2, y2, c='r')\n",
    "ax.scatter(x_g, y_g, c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=20\n",
    "# ax.scatter(x[k], y[k], c='r')\n",
    "# ax.scatter(x_g[15], y_g[15], c='g')\n",
    "ax.scatter(x2[k], y2[k], c='r')\n",
    "# ax.scatter(x_g, y_g, c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=17\n",
    "# ax.scatter(x[k], y[k], c='r')\n",
    "# ax.scatter(x_g[15], y_g[15], c='g')\n",
    "# ax.scatter(x, y, c='r')\n",
    "ax.scatter(x_g[k], y_g[k], c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file into a NumPy array\n",
    "# img = plt.imread('image.png')\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the image using imshow()\n",
    "ax.imshow(img)\n",
    "\n",
    "# Generate some random x and y coordinates\n",
    "# x = np.random.randint(0, img.shape[1], size=50)\n",
    "# y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "# Plot the points using scatter()\n",
    "k=24\n",
    "jk=30\n",
    "ax.scatter(x[k], y[k], c='r')\n",
    "ax.scatter(x_g[jk], y_g[jk], c='g')\n",
    "# ax.scatter(x, y, c='r')\n",
    "# ax.scatter(x_g, y_g, c='g')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "y_idexed=[]\n",
    "sums=[]\n",
    "for i in range(len(x)):\n",
    "    min=+9999\n",
    "    index=-1\n",
    "    for j in range(len(x_g)):\n",
    "        if j in y_idexed:\n",
    "            continue\n",
    "        p1=[x[i],y[i]]\n",
    "        p2=[x_g[j],y_g[j]]\n",
    "        if abs(math.dist(p1,p2))<min:\n",
    "            min=abs(math.dist(p1,p2))\n",
    "            index=j\n",
    "    if index not in y_idexed:\n",
    "        y_idexed.append(index)\n",
    "    sums.append(math.dist([x[i],y[i]],[x_g[index],y_g[index]]))\n",
    "    print(i,index)\n",
    "print(np.mean(sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "y_idexed=[]\n",
    "sums=[]\n",
    "for i in range(len(x)):\n",
    "    min=+9999\n",
    "    index=-1\n",
    "    for j in range(len(x_g)):\n",
    "        # if j in y_idexed:\n",
    "        #     continue\n",
    "        p1=[x[i],y[i]]\n",
    "        p2=[x_g[j],y_g[j]]\n",
    "        if abs(math.dist(p1,p2))<min:\n",
    "            min=abs(math.dist(p1,p2))\n",
    "            index=j\n",
    "    # if index not in y_idexed:\n",
    "    y_idexed.append(index)\n",
    "    sums.append(math.dist([x[i],y[i]],[x_g[index],y_g[index]]))\n",
    "    print(i,index)\n",
    "print(np.mean(sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "y_idexed=[]\n",
    "sums=[]\n",
    "all_dis=[]\n",
    "for i in range(len(x)):\n",
    "    min=+9999\n",
    "    index=-1\n",
    "    temp=[]\n",
    "    for j in range(len(x_g)):\n",
    "        if j in y_idexed:\n",
    "            continue\n",
    "        p1=[x[i],y[i]]\n",
    "        p2=[x_g[j],y_g[j]]\n",
    "        dis=abs(math.dist(p1,p2))\n",
    "        temp.append(dis)\n",
    "    all_dis.append(temp)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in all_dis:\n",
    "    print(sorted(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=model.apply_detecting(image=img)\n",
    "x=[]\n",
    "y=[]\n",
    "for a in arr:\n",
    "    x.append(a[0])\n",
    "    y.append(a[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(),'model_state_150_resnet101.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(),'model_state_150_resnet101.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('pipnet-wflw-resnet101-epoch199-loss1.0198.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:/code/landmark/our_dataset/train.txt\",'r') as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    spets=lines[i].split(' ')\n",
    "    spets.pop(1)\n",
    "    spets.pop(1)\n",
    "    lines[i]=' '.join(spets)\n",
    "with open(\"E:/code/landmark/our_dataset/train2.txt\", 'w') as f:\n",
    "    for item in lines:\n",
    "        f.write(item)\n",
    "\n",
    "with open(\"E:/code/landmark/our_dataset/test.txt\",'r') as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    spets=lines[i].split(' ')\n",
    "    spets.pop(1)\n",
    "    spets.pop(1)\n",
    "    lines[i]=' '.join(spets)\n",
    "with open(\"E:/code/landmark/our_dataset/test2.txt\", 'w') as f:\n",
    "    for item in lines:\n",
    "        f.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from torchlm.models import pipnet\n",
    "# will auto download pretrained weights from latest release if pretrained=True\n",
    "model = pipnet(backbone=\"resnet101\", pretrained=True, num_nb=10, num_lms=29, net_stride=32,\n",
    "               input_size=256, meanface_type=\"cofw\", backbone_pretrained=True)\n",
    "# model.apply_freezing(backbone=True)\n",
    "# model.apply_training(\n",
    "#     annotation_path=\"E:/code/landmark/data/300w/images/train.txt\",  # or fine-tuning your custom data\n",
    "#     num_epochs=10,\n",
    "#     learning_rate=0.0001,\n",
    "#     save_dir=\"E:/code/landmark/data/300w/images\",\n",
    "#     save_prefix=\"pipnet-300w-resnet18\",\n",
    "#     save_interval=1,\n",
    "#     logging_interval=1,\n",
    "#     device=\"cuda\",\n",
    "#     coordinates_already_normalized=True,\n",
    "#     batch_size=16,\n",
    "#     num_workers=4,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "\n",
    "from torchlm.models import pipnet\n",
    "import torchlm\n",
    "#  \n",
    "model.apply_freezing(backbone=False)\n",
    "# generate your custom meanface.\n",
    "custom_meanface, custom_meanface_string = torchlm.data.annotools.generate_meanface(\n",
    "  annotation_path=\"E:/code/landmark/daghigihi/train.txt\",\n",
    "  coordinates_already_normalized=True)\n",
    "\n",
    "# setting up your custom meanface\n",
    "model.set_custom_meanface(custom_meanface_file_or_string=custom_meanface_string)\n",
    "model.apply_training(\n",
    "    annotation_path=\"E:/code/landmark/daghigihi/train.txt\",  # or fine-tuning your custom data\n",
    "    num_epochs=200,\n",
    "    learning_rate=3e-4,\n",
    "    save_dir=\"./save/pipnet\",\n",
    "    save_prefix=\"pipnet-wflw-resnet101\",\n",
    "    save_interval=2,\n",
    "    logging_interval=1,\n",
    "    device=\"cuda\",\n",
    "    coordinates_already_normalized=True,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NME, FR, AUC = model.apply_evaluating(\n",
    "    annotation_path=\"E:/code/landmark/our_dataset/train.txt\",\n",
    "    norm_indices=[22, 18],  # the indexes of two eyeballs.\n",
    "    coordinates_already_normalized=True, \n",
    "    eval_normalized_coordinates=False\n",
    ")\n",
    "print(f\"NME: {NME}, FR: {FR}, AUC: {AUC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply_detecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:/code/landmark/our_dataset/train.txt\",delimiter=' ',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('E:/code/landmark/save/pipnet/pipnet-wflw-resnet101-epoch191-loss0.1577.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=[\"Tr'\",\n",
    " \"G'\",\n",
    " \"N'\",\n",
    " 'Prn',\n",
    " 'Sn',\n",
    " 'Ls',\n",
    " 'Sts',\n",
    " 'Sti',\n",
    " 'Li',\n",
    " 'Sbl',\n",
    " \"Me'\",\n",
    " 'MBL',\n",
    " 'MBR',\n",
    " 'EAL',\n",
    " 'EAR',\n",
    " \"Ft'L\",\n",
    " \"Ft'R\",\n",
    " 'EnL',\n",
    " 'EnR',\n",
    " 'PupL',\n",
    " 'PupR',\n",
    " 'ExL',\n",
    " 'ExR',\n",
    " 'MfL',\n",
    " 'MfR',\n",
    " 'AlL',\n",
    " 'AlR',\n",
    " 'CpL',\n",
    " 'CpR',\n",
    " 'ChL',\n",
    " 'ChR',\n",
    " 'MEL',\n",
    " 'MER',\n",
    " \"Zy'L\",\n",
    " \"Zy'R\",\n",
    " \"Go'L\",\n",
    " \"Go'R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_result=pd.DataFrame(columns=['file','type'])\n",
    "for tag in tags:\n",
    "    df_result[tag+'_x']=None\n",
    "    df_result[tag+'_y']=None\n",
    "\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "all_sum=[]\n",
    "model.eval()\n",
    "outputs=[]\n",
    "for i in range(len(df)):\n",
    "    if i==3000:\n",
    "        break\n",
    "    img = plt.imread(df.iloc[i][0])\n",
    "    x_g=[]\n",
    "    y_g=[]\n",
    "    for j in range(1,len(df.iloc[i]),2):\n",
    "        x_g.append(float(df.iloc[i][j])*256)\n",
    "\n",
    "    for j in range(2,len(df.iloc[i]),2):\n",
    "        y_g.append(float(df.iloc[i][j])*256)\n",
    "\n",
    "    output=model.apply_detecting(image=img)\n",
    "    xx=torch.load('lms_pred_x.pt')*256\n",
    "    yy=torch.load('lms_pred_y.pt')*256\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for a in xx.cpu():\n",
    "        x.append(a.item())\n",
    "    for a in yy:\n",
    "        y.append(a.item())\n",
    "    outputs.append(output)\n",
    "    x2=output[:,0]\n",
    "    y2=output[:,1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the image using imshow()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Generate some random x and y coordinates\n",
    "    # x = np.random.randint(0, img.shape[1], size=50)\n",
    "    # y = np.random.randint(0, img.shape[0], size=50)\n",
    "\n",
    "    # Plot the points using scatter()\n",
    "    k=20\n",
    "    # ax.scatter(x[k], y[k], c='r')\n",
    "    # ax.scatter(x_g[15], y_g[15], c='g')\n",
    "    ax.scatter(x, y, c='r')\n",
    "    ax.scatter(x_g, y_g, c='g')\n",
    "    temp=[]\n",
    "    temp.append(df.iloc[i][0][df.iloc[i][0].rfind('\\\\')+1:])\n",
    "    temp.append('ground_truth')\n",
    "    for r in range(len(x_g)):\n",
    "        temp.append(x_g[r])\n",
    "        temp.append(y_g[r])\n",
    "    # df_result = df_result.append(pd.Series(temp), ignore_index=True)\n",
    "    df_result.loc[len(df_result)]=temp\n",
    "\n",
    "    temp=[]\n",
    "    temp.append(df.iloc[i][0][df.iloc[i][0].rfind('\\\\')+1:])\n",
    "    temp.append('model_prediction')\n",
    "    for r in range(len(x)):\n",
    "        temp.append(x[r])\n",
    "        temp.append(y[r])\n",
    "    # df_result = df_result.append(pd.Series(temp), ignore_index=True)\n",
    "    df_result.loc[len(df_result)]=temp\n",
    "\n",
    "    \n",
    "    \n",
    "    # with open('E:/code/landmark/our_dataset/landmarks.txt', 'a') as file:\n",
    "    # # Write content to the file\n",
    "    #     file.write(\"{}\\n\".format(df.iloc[i][0]))\n",
    "    #     for j in range(len(x)):\n",
    "    #         file.write('ground_truth:\\n')\n",
    "    #         file.write('{} {}\\n'.format(x_g[j],y_g[j]))\n",
    "            \n",
    "    #         file.write('model predict:\\n')\n",
    "    #         file.write('{} {}\\n'.format(x[j],y[j]))\n",
    "\n",
    "    #         file.write('\\n')\n",
    "\n",
    "\n",
    "    plt.savefig(\"E:/code/landmark/our_dataset/results/{}.png\".format(i))\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "#     import math\n",
    "#     import numpy as np\n",
    "#     y_idexed=[]\n",
    "#     sums=[]\n",
    "#     for i in range(len(x)):\n",
    "#         min=+9999\n",
    "#         index=-1\n",
    "#         for j in range(len(x_g)):\n",
    "#             # if j in y_idexed:\n",
    "#             #     continue\n",
    "#             p1=[x[i],y[i]]\n",
    "#             p2=[x_g[j],y_g[j]]\n",
    "#             if abs(math.dist(p1,p2))<min:\n",
    "#                 min=abs(math.dist(p1,p2))\n",
    "#                 index=j\n",
    "#         # if index not in y_idexed:\n",
    "#         y_idexed.append(index)\n",
    "#         sums.append(math.dist([x[i],y[i]],[x_g[index],y_g[index]]))\n",
    "#         # print(i,index)\n",
    "#     # print(np.mean(sums))\n",
    "#     print(len(y_idexed))\n",
    "#     all_sum.append(np.mean(sums))\n",
    "# print(np.mean(all_sum))\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('E:/code/landmark/our_dataset/result_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BRACS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
